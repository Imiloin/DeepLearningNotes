\chapter[Improving Deep Neural Networks]{Improving Deep Neural Networks\setcounter{footnote}{0}\footnote{Hyperparameter Tuning, Regularization and Optimization}}

%%%
\section{Setting up Your Machine Learning Application}

%%%%
\subsection{Train/Dev/Test sets}
对于数据集，我们通常将其分为三个部分：
\begin{itemize}
    \item \textbf{Training set}: 训练集，用于训练模型。一般占60\%。
    \item \textbf{Dev (development) set}: 开发集，用于调整模型的超参数。一般占20\%。
    \item \textbf{Test set}: 测试集，用于测试模型的性能。一般占20\%。
\end{itemize}
有时候，我们会将数据集仅分为训练集和开发集，而没有测试集。这时候，我们通常将二者的比例调整为70\%和30\%。

%%%%
\subsection{Bias and Variance}
\textbf{偏差（Bias）}描述了模型的预测值与真实值之间的差距。Bias越大，说明模型越不准确。
而\textbf{方差（Variance）}描述了模型的预测值与真实值之间的差距的方差。Variance越大，说明模型越不稳定。
\begin{figure}[h!bt]
    \centering
    \subfigure[High Bias]{
        \begin{minipage}[t]{0.3\textwidth}
            \centering
            \includegraphics[scale=0.75]{high_bias.pdf}
        \end{minipage}
    }%
    \subfigure[Just Right]{
        \begin{minipage}[t]{0.3\textwidth}
            \centering
            \includegraphics[scale=0.75]{just_right.pdf}
        \end{minipage}
    }%
    \subfigure[High Variance]{
        \begin{minipage}[t]{0.3\textwidth}
            \centering
            \includegraphics[scale=0.75]{high_variance.pdf}
        \end{minipage}
    }%
    \centering
    \caption{Bias and Variance}
    \label{fig:bias-variance}
\end{figure}

\textbf{高偏差（High bias）}通常表示模型欠拟合，即模型的复杂度不够，无法拟合数据。这可以体现在模型在训练集上的误差和在开发集上的误差都很大，且二者之间的差距不大。
而\textbf{高方差（High variance）}通常表示模型过拟合，即模型的复杂度过高，导致模型过于敏感，无法泛化。这可以体现在模型在训练集上的误差很小，但在开发集上的误差很大。
若高偏差和高方差同时存在，则会体现在模型在训练集上的误差和在开发集上的误差都很大，且开发集上的误差明显大于训练集上的误差。

当我们发现模型的偏差很大时，可以尝试使用更大的网络、训练更长的时间、使用更好的优化算法等来提高模型的复杂度，从而减小偏差。
而当我们发现模型的方差很大时，可以尝试使用更多的数据、使用正则化、使用dropout等来减小模型的复杂度，从而减小方差。

%%%
\section{Regularizing Your Neural Network}

在本章中会引入一些新的符号，如表~\ref{tab:notations-chap2} 所示。

\begin{table}[h!tbp]
    \centering
    \begin{threeparttable}
    %%
    \caption{Appended Notations in Chapter 2}
    %
    \begin{tabular}{clcc}
        \toprule
                                        & \textbf{Notation}                                                                     & \textbf{Description} & \textbf{Meaning}                                                   \\ 
        \midrule
        \multirow{1}{*}{Sizes}          & $\verb|batch_size| \in \mathbb{Z}^+$								                    & value                & 每个 \verb|mini_batch| 使用的样本数                                  \\
        \midrule
        \multirow{9}{*}{Objects}        & $X^{\{t\}} \in \mathbb{R}^{n_x \times \mathtt{batch\_size}}$                          & matrix               & 第$t$个 \verb|mini_batch| 的输入矩阵                                 \\
                                        & $Y^{\{t\}} \in {\mathbb{R}^{n_y \times \mathtt{batch\_size}}}$                        & matrix               & 第$t$个 \verb|mini_batch| 的样本标签矩阵                              \\									
                                        & $\hat{Y}^{\{t\}} / A^{[L]\{t\}} \in {\mathbb{R}^{n_y \times \mathtt{batch\_size}}}$   & matrix               & 第$t$个 \verb|mini_batch| 的标签预测值矩阵   						   \\
                                        & $v_{\d \mathrm{var}} \in \mathbb{R}^{\mathtt{size}(\d \mathrm{var})}$                 & matrix               & 梯度 $\d \mathrm{var}$ 第一矩估计的移动平均值                          \\
                                        & $s_{\d \mathrm{var}} \in \mathbb{R}^{\mathtt{size}(\d \mathrm{var})}$                 & matrix               & 梯度 $\d \mathrm{var}$ 第二矩估计的移动平均值                         \\
                                        & $Z^{[l]}_{\mathrm{norm}} \in \mathbb{R}^{n^{[l]} \times {m}}$                         & matrix               & 第$l$层的归一化后的线性输出矩阵                                       \\
                                        & $\tilde{Z}^{[l]} \in \mathbb{R}^{n^{[l]} \times {m}}$                                 & matrix               & 第$l$层的缩放归一化线性输出矩阵                                       \\
                                        & $\gamma^{[l]} \in \mathbb{R}^{n^{[l]} \times 1}$                                      & vector               & 第$l$层的缩放因子向量                                                 \\
                                        & $\beta^{[l]} \in \mathbb{R}^{n^{[l]} \times 1}$                                       & vector               & 第$l$层的平移因子向量                                                 \\
        \midrule
        \multirow{5}{*}{HP\,\tnote{a}}  & $\lambda \in \mathbb{R}^+_0$                                                          & value                & 正则化参数                                                             \\  
                                        & \verb|keep_prob| $\in (0,1]$                                                          & value                & Dropout算法的保留概率                                                   \\ 
                                        & \verb|epoch| $\in \mathbb{Z}^+$                                                       & value                & 训练过程中训练集被遍历的次数                                           \\
                                        & $\beta_1 \in [0,1)$                                                                   & value                & 第一矩估计的衰减率                                                    \\ 
                                        & $\beta_2 \in [0,1)$                                                                   & value                & 第二矩估计的衰减率                                                     \\
        \midrule
        \multirow{4}{*}{Other}          & $J^{\{t\}}$                                                                           & function             & 第$t$个 \verb|mini_batch| 的代价函数                                   \\ 
                                        & $\varepsilon \in \mathbb{R}^+$                                                        & value                & 数值稳定性参数                                                        \\
                                        & $\mu^{[l]} \in \mathbb{R}^{n^{[l]} \times 1}$                                         & vector               & 第$l$层的均值向量                                                       \\
                                        & $\sigma^{[l]} \in \mathbb{R}^{n^{[l]} \times 1}$                                      & vector               & 第$l$层的标准差向量                                                     \\
        \bottomrule
    \end{tabular}
    %
    \label{tab:notations-chap2} %
    \begin{tablenotes}
        \item[*] 通常情况下${\{t\}}$表示第$t$个batch。
        \item[a] Hyperparameters.
    \end{tablenotes}
    %%
    \end{threeparttable}
\end{table}

%%%%
\subsection{Regularization}
\index{Regularization}

正则化（Regularization）是一种减小模型复杂度的方法，可以防止模型过拟合。
正则化的方法有很多，这里介绍两种常用的正则化方法：$L_2$正则化和Dropout。

\begin{hint}
    正则化的目的是改变（通常是缩小）在更新权重和偏置时的梯度值，其本身并不干预模型的前向传播和反向传播过程。
\end{hint}

\subsubsection{$\mathsf{L_2}$ regularization}

\textbf{$\bm{L_2}$正则化（$\bm{L_2}$ regularization）}也称为权重衰减（Weight Decay），是一种常用的正则化方法。
$L_2$正则化通过在代价函数中添加一个权重
\footnote{一般不对偏置做$L_2$正则化，避免影响神经元的激活阈值。}
的$L_2$范数
\footnote{$L_2$范数是针对向量的，而Frobenius范数是针对矩阵的，在这里并没有做严谨的区分。}
惩罚项来实现，这个惩罚项模型权重的平方成正比。这样做的目的是鼓励模型使用较小的权重，从而减少模型的复杂度。

$L_2$范数的定义是，对于一个长度为$n$的向量$w$，其$L_2$范数为：
\begin{equation}
    ||w||_2 = \sqrt{\sum_{j=1}^nw_j^2}
\end{equation}

使用$L_2$正则化后，代价函数中添加了各层权重信息的Frobenius范数，其计算公式为：
\begin{equation}
    J = \frac{1}{m}\sum_{i=1}^mL(\hat{y}^{(i)}, y^{(i)}) + \frac{\lambda}{2m}\sum_{l=1}^L||W^{[l]}||_{\mathrm{F}}^2
\end{equation}
其中$\lambda$为正则化参数，用于控制正则化的强度。$||W^{[l]}||_2^2$表示第$l$层权重Frobenius范数的平方，即
\begin{equation}
    ||W^{[l]}||_{\mathrm{F}}^2 = \sum_{i=1}^{n^{[l]}}\sum_{j=1}^{n^{[l-1]}}(W_{ij}^{[l]})^2
\end{equation}
添加这个惩罚项后，代价函数对权重的梯度为：
\begin{equation}
    \frac{\d J}{\d W^{[l]}} = \frac{\d J}{\d Z^{[l]}} A^{[l-1] \mathrm{T}} + \frac{\lambda}{m}W^{[l]}
\end{equation}
其他的梯度表达式保持不变（证明略）。

\subsubsection{Dropout}
\index{Dropout}

\textbf{Dropout}是一种常用的正则化方法，可以防止模型过拟合。Dropout的基本思想是，在每次迭代中，随机地关闭一些神经元，从而减小模型的复杂度，相当于只训练了完整模型的一个子集。
Dropout 是以层为单位来使用的，即在设定的某些 Dropout 层中，每次迭代时，以一定的概率关闭其中的神经元（每次迭代可以关闭不同的神经元）。

需要注意，“关闭”神经元并不是将神经元中的权重和偏置清零，而只是将其输出置零。

\begin{figure}[h!bt]
    \centering
    \subfigure[随机选取神经元]{
        \begin{minipage}[t]{0.48\textwidth}
            \centering
            \includegraphics[width=0.8\textwidth]{dropout_1.pdf}
        \end{minipage}
    }%
    \subfigure[输出置零]{
        \begin{minipage}[t]{0.48\textwidth}
            \centering
            \includegraphics[width=0.8\textwidth]{dropout_2.pdf}
        \end{minipage}
    }%
    \centering
    \caption{Dropout}
    \label{fig:dropout}
\end{figure}

一种常见的Dropout实现为Inverted dropout。假设第$l$层被设置为Dropout层，设置一个保留概率 \verb|keep_prob| ，
则在每次迭代的前向传播中，先用原有的方式计算出第$l$层的激活值$A^{[l]}$，然后构造一个布尔矩阵（mask）$D^{[l]}$，其中的元素以概率 \verb|keep_prob| 取值为1，以概率 \verb|1-keep_prob| 取值为0。
\footnote{严格来说，“关闭”某些神经元应当将$A^{[l]} \in \mathbb{R}^{n^{[l]} \times {m}}$的某些行随机置零，而不是对所有元素随机置零。对所有元素随机置零相当于在同一轮迭代中每个样本都关闭了不同的神经元，但这样做也是可行的。}
\begin{equation}
    \mathtt{D^{\textcolor{Magenta}{[}l\textcolor{Magenta}{]}}} = \mathtt{np.random.rand\textcolor{yellow}{(} A^{\textcolor{Magenta}{[}l\textcolor{Magenta}{]}}.shape\textcolor{Magenta}{[}\textcolor{green}{0}\textcolor{Magenta}{]}, A^{\textcolor{Magenta}{[}l\textcolor{Magenta}{]}}.shape\textcolor{Magenta}{[}\textcolor{green}{1}\textcolor{Magenta}{]} \textcolor{yellow}{)} < keep\_prob}
\end{equation}
将这个布尔矩阵与$A^{[l]}$相乘，即可将第$l$层的部分输出置零
\begin{equation}
    \mathtt{A^{\textcolor{Magenta}{[}l\textcolor{Magenta}{]}}} = \mathtt{np.multiply\textcolor{yellow}{(} A^{\textcolor{Magenta}{[}l\textcolor{Magenta}{]}}, D^{\textcolor{Magenta}{[}l\textcolor{Magenta}{]}} \textcolor{yellow}{)}}
\end{equation}
为了补偿训练过程中由于 Dropout 导致的输出值的减少，需要进行一次缩放，即
\begin{equation}
    \mathtt{A^{\textcolor{Magenta}{[}l\textcolor{Magenta}{]}}} /= \mathtt{keep\_prob}
\end{equation}
将这个值作为第$l$层的输出$A^{[l]}$。这个操作应在计算第$l+1$层之前完成。

在反向传播中，使用这些经过 Dropout 的各层输出来计算梯度来更新权重和偏置。同时，$\d A^{[l]}$也需要进行类似的操作使其与$A^{[l]}$对应，即
\begin{align}
    \mathtt{dA^{\textcolor{Magenta}{[}l\textcolor{Magenta}{]}}} &= \mathtt{np.multiply\textcolor{yellow}{(} dA^{\textcolor{Magenta}{[}l\textcolor{Magenta}{]}}, D^{\textcolor{Magenta}{[}l\textcolor{Magenta}{]}} \textcolor{yellow}{)}} \\
    \mathtt{dA^{\textcolor{Magenta}{[}l\textcolor{Magenta}{]}}} &/= \mathtt{keep\_prob}
\end{align}
这个操作应在计算第$l-1$层之前完成。

从结果上看，Dropout 操作相当于这一轮迭代中的训练的神经元数“减少”了，这可以降低模型对单个神经元的依赖，从而提高模型的泛化能力。

在评估模型或者使用模型进行预测时（此时只有前向传播），需要关闭Dropout。这是为了确保模型的输出与训练阶段保持一致，从而准确评估模型在未见数据上的性能。

\subsubsection{Other regularization methods}

除了$L_2$正则化和Dropout，还有一些其他的正则化方法，如数据增强（Data Augmentation）、早停（Early Stopping）等。

数据增强是一种简单有效的正则化方法，其基本思想是通过对训练集中的数据进行一些随机变换，从而生成更多的训练数据。
例如，对于图像分类问题，可以对图像进行一些随机的旋转、平移、缩放等操作，将其作为新增的训练数据。

早停的基本思想是在训练过程中，当模型在开发集上的误差连续一段时间不再下降时，就停止训练。
这样可以防止模型过拟合，但需要注意的是，早停的效果很大程度上依赖于开发集的选择。

\subsection{Normalizing Inputs}
\index{Normalization}

在训练神经网络时，我们通常会对输入数据进行\textbf{归一化处理（Normalization）}。
归一化可以确保数值在可接受的范围内，将所有特征重现在相同的尺度上，提高算法的数值稳定性。

数据归一化通常包括两个步骤：减去平均值（使得归一化后的数据具有零均值）和除以标准差（使得归一化后的数据具有单位方差）。
这种方法也被称为 Z-score 标准化或标准化。在标准化后，数据的均值为0，标准差为1。

\begin{figure}[h!bt]
    \centering
    \subfigure[Before Normalization]{
        \begin{minipage}[t]{0.48\textwidth}
            \centering
            \includegraphics[scale=0.75]{norm_before.pdf}
        \end{minipage}
    }%
    \subfigure[After Normalization]{
        \begin{minipage}[t]{0.48\textwidth}
            \centering
            \includegraphics[scale=0.75]{norm_after.pdf}
        \end{minipage}
    }%
    \centering
    \caption{Normalization}
    \label{fig:normalization}
\end{figure}

在 python 中，可以很方便地实现输入数据的归一化
\begin{python}
X -= np.mean(X, axis=0)
X /= np.std(X, axis=0)
\end{python}

%%%
\section{Optimization Algorithms}

%%%%
\subsection{Mini-batch Gradient Descent}
\index{Mini-batch Gradient Descent}

之前的梯度下降算法都是基于整个训练集的，即每次迭代都要计算整个训练集的代价函数和梯度，然后更新权重和偏置。
这样的梯度下降算法称为\textbf{批量梯度下降（Batch Gradient Descent）}，其缺点是每次更新梯度都需要完整遍历整个训练集，计算量很大，效率很低。
一种更好的方法是将训练集分成若干个子集，每次迭代只计算一个子集的代价函数和梯度，然后更新权重和偏置。
这样的梯度下降算法称为\textbf{小批量梯度下降（Mini-batch Gradient Descent）}。

\begin{hint}
    权重$W$和偏置$b$的规模完全由各层节点数$n^{[l]},\; 0 \leqslant l \leqslant L$决定，与样本数$m$无关。对于不同的样本数$m$，只需要调整$X$和$Y$的规模即可，而网络内部的节点数不需要调整就能适应不同规模的样本。
    这也是 Mini-batch 优化算法能实现的基础。
\end{hint}

在实现时，设定一个 \verb|mini_batch_size| （可简写为 \verb|batch_size|） ，将训练集打乱顺序（Shuffle）（打乱顺序时，$X$和$Y$需要对应），
然后将其分成若干个大小为 \verb|batch_size| 的子集（Partition）。
对于不同的 \verb|mini_batch| ，仍共享相同的权重和偏置，即训练的仍是同一个网络。

前向传播的过程与之前的算法相同，相当于将第$t$个子集$X^{\{t\}}$作为输入矩阵，依次计算出各层的输出矩阵$A^{[l]}$。
应当注意，此时输入的样本的规模相当于从$m$变成了 \verb|batch_size|，在计算代价函数时需要除以 \verb|batch_size| 而不是$m$。例如在使用 $L_2$ 正则化时，代价函数的计算公式为
\begin{equation}
    J^{\{t\}} = \frac{1}{\mathtt{batch\_size}}\sum_{i=1}^\mathtt{batch\_size} L(\hat{y}^{(i)}, y^{(i)}) + \frac{\lambda}{2\;\mathtt{batch\_size}}\sum_{l=1}^L||W^{[l]}||_{\mathrm{F}}^2
\end{equation}
不同的 \verb|mini_batch| 包含不同的样本，因此即便使用同样的权重和偏置，不同的 \verb|mini_batch| 也会得到不同的代价函数。
在使用小批量梯度下降时，代价函数值并不是像之前那样单调递减的，而是有一定的波动。

\begin{figure}[h!bt]
    \centering
    \includegraphics[scale=0.6]{mini-batch_cost.pdf}
    \caption{Cost Function in Mini-batch Gradient Descent}
    \label{fig:mini-batch_cost}
\end{figure}

反向传播的过程也与之前的算法相同，依次计算出各层的梯度矩阵$\d W^{[l]}$和$\d b^{[l]}$，然后更新权重和偏置。
为了保证梯度值与批量梯度下降的比例不变，反向传播的输出层初始值也要做相应改变
\begin{equation}
    \frac{\d J^{\{t\}}}{\d A^{[L]\{t\}}} 
    = \frac{1}{\mathtt{batch\_size}} \left(-\frac{Y^{\{t\}}}{A^{[L]\{t\}}} + \frac{1 - Y^{\{t\}}}{1 - A^{[L]\{t\}}}\right)
\end{equation}
如果不做这个改变，反向传播的输出层初始值将存在一个比例因子，相当于改变了学习率。

当所有的 \verb|mini_batch| 都遍历完一遍训练集后，称为完成了一个 \texttt{\textbf{epoch}}。
训练过程中使用的 \verb|epoch| 数也是一个超参数，表示了整个训练集被遍历的次数。在每个 \verb|epoch| 结束后，可以重新打乱训练集的顺序，然后再次分成若干个 \verb|mini_batch| 继续训练以增强随机性。

当数据量非常大时，使用小批量梯度下降算法已被证明是一种有效的优化算法，可以加快训练速度。
小批量梯度下降算法每次更新权重和偏置只需要计算一个 \verb|mini_batch| 的代价函数和梯度，相比于批量梯度下降算法大大减少了计算量，可以更快地收敛。

\verb|batch_size| 的取值一般为2的幂次方，如32、64、128等，一般不会超过512。过大的 \verb|batch_size| 会导致训练速度变慢，而过小的 \verb|batch_size| 会导致训练过程中的代价函数波动较大。

%%%%
\subsection{Gradient Descent with Momentum}

\subsubsection{Exponentially Weighted Averages}

\textbf{指数加权平均（Exponentially Weighted Averages）}是一种常用的序列数据平滑方法，可以用于计算梯度的指数加权平均值。

给定一个序列$\{a_1, a_2, \cdots, a_n\}$，其指数加权平均值的递推公式为
\begin{equation}
    v_t = \beta v_{t-1} + (1 - \beta)a_t
    \label{eq:ewa}
\end{equation}
其中$v_0 = 0$，$\beta$为衰减率，$0 < \beta < 1$。
将式~\eqref{eq:ewa} 展开，可得
\begin{equation}
    \begin{aligned}
        v_t &= (1 - \beta)a_t + \beta v_{t-1} \\
            &= (1 - \beta)a_t + (1 - \beta)\beta a_{t-1} + \beta^2 v_{t-2} \\
            &= (1 - \beta)a_t + (1 - \beta)\beta a_{t-1} + (1 - \beta)\beta^2 a_{t-2} + \beta^3 v_{t-3} \\
            &= \cdots \\
            &= (1 - \beta)a_t + (1 - \beta)\beta a_{t-1} + (1 - \beta)\beta^2 a_{t-2} + \cdots + (1 - \beta)\beta^{t-1}a_1 + \beta^t v_0 \\
            &= (1 - \beta)\sum_{i=1}^t\beta^{t-i}a_i
    \end{aligned}
    \label{eq:ewa_expand}
\end{equation}
可以看出，指数加权平均值$v_t$是序列$\{a_1, a_2, \cdots, a_t\}$的加权平均值，权重为$\beta$的指数函数。
这类似于$v_t$“记住”了序列当前及过去的所有值，但是对于序列中较早的值，其权重会随着时间的推移而指数级衰减。
对于式~\eqref{eq:ewa_expand} 中的 $a_i$，可以认为当其权重小于 $a_t/\mathrm{e}$ 时，其对 $v_t$ 的贡献可以忽略不计。
通常 $\beta$ 是一个接近于1的值，由于
\begin{equation}
    \lim_{\beta \to 1}  \beta^{\frac{\scriptstyle 1}{\scriptstyle 1-\beta}} = \frac{1}{\mathrm{e}}
\end{equation}
可以发现，$v_t$近似于“记住”了从$a_t$开始向前的$1/(1-\beta)$个值。当$\beta=0.9$时，$v_t$可理解为包含了过去10个值的信息。

指数加权平均值对序列$\{a_1, a_2, \cdots, a_t\}$进行了平滑处理，使得序列中的噪声对结果的影响减小。
将指数加权平均应用于梯度的计算中，可以减少梯度的震荡，从而加快梯度下降的收敛速度。

\subsubsection{Bias Correction in Exponentially Weighted Averages}

在使用指数加权平均时，由于$v_0 = 0$，在初始阶段，$v_t$的值会接近0，导致$v_t$的绝对值偏低。
当序列$\{a_1, a_2, \cdots, a_t\}$为全1序列时，$v_t$的值为
\begin{equation}
    v_t = (1 - \beta)\sum_{i=1}^t\beta^{t-i} = (1 - \beta)\frac{1 - \beta^t}{1 - \beta} = 1 - \beta^t
\end{equation}
期望的$v_t^{\mathrm{corrected}}$的值为$1$，因此可以对$v_t$进行偏差修正（Bias Correction），即
\begin{equation}
    v_t^{\mathrm{corrected}} = \frac{v_t}{1 - \beta^t}
\end{equation}
在实际使用中，常常忽略掉偏差修正以避免额外的计算量，因为在训练的后期，$v_t$的值会趋于稳定，偏差修正的影响不大。

\begin{figure}[h!bt]
    \centering
    \includegraphics[scale=0.6]{ewa.pdf}
    \caption{Exponentially Weighted Averages}
    \label{fig:ewa}
\end{figure}

\subsubsection{Gradient Descent with Momentum}

动量梯度下降（Gradient Descent with Momentum）是一种基于指数加权平均的优化算法，可以加快梯度下降的收敛速度。
动量梯度下降将梯度的指数加权平均值作为梯度的更新值，即
\begin{equation}
    \begin{aligned}
        v_{\d \mathrm{var}} &= \beta_1 v_{\d \mathrm{var}} + (1 - \beta_1)\d \mathrm{var} \\
        \d \mathrm{var} &= v_{\d \mathrm{var}}
    \end{aligned}
    \label{eq:momentum}
\end{equation}
其中$\d \mathrm{var}$可以是$\d W^{[l]}$或$\d b^{[l]}$，$\beta_1$为衰减率，$0 < \beta_1 < 1$。
整个梯度$\d \mathrm{var}$的序列由每轮迭代的梯度组成。
$v_{\d \mathrm{var}}$是梯度的一阶矩（First Moment）估计，也称为动量（Momentum）。
\footnote{式~\eqref{eq:momentum} 酷似动量守恒的表达式。}
动量可以平均梯度的方向，从而减少梯度下降的震荡，常常与 Mini-batch 梯度下降一起使用。

注意式~\eqref{eq:momentum} 是代码实现的方法，其是一个递推公式，初始值是0。这样做可以避免使用额外的变量，节省内存空间。

%%%%
\subsection{RMSprop}

动量梯度下降是对梯度的一阶矩进行指数加权平均，而RMSprop是对梯度的二阶矩进行指数加权平均。
其表达式为
\begin{equation}
    \begin{aligned}
        s_{\d \mathrm{var}} &= \beta_2 s_{\d \mathrm{var}} + (1 - \beta_2)(\d \mathrm{var})^{\tikzmarknode[outer ysep=2pt]{sq}{2}} \\
        \d \mathrm{var} &= \frac{\d \mathrm{var}}{\sqrt{s_{\d \mathrm{var}}} + \varepsilon}
    \end{aligned}
    \annotate[yshift=1em]{above}{sq}{element-wise square}
    \label{eq:rmsprop}
\end{equation}
同样地，$\d \mathrm{var}$可以是$\d W^{[l]}$或$\d b^{[l]}$，$\beta_2$为衰减率，$0 < \beta_2 < 1$。
而$\varepsilon$为数值稳定性参数，通常取$10^{-8}$，用于避免分母为0。
式中的$\sqrt{s_{\d \mathrm{var}}}$是为了保证齐次性。
使用 \verb|np.square()| 可以实现逐元素的平方。

由于
\begin{equation}
    s_t = (1 - \beta_2)\sum_{i=1}^t\beta_2^{t-i}a_i^2
\end{equation}
可以看出，$s_t$是序列$\{a_1^2, a_2^2, \cdots, a_t^2\}$的加权平均值，权重为$\beta_2$的指数函数。
与一阶矩类似，也可以进行偏差修正，即
\begin{equation}
    s_t^{\mathrm{corrected}} = \frac{s_t}{1 - \beta_2^t}
\end{equation}

%%%%
\subsection{Adam Optimization Algorithm}
\index{Adam Algorithm}

\textbf{Adam算法（Adam Optimization Algorithm）}是一种结合了动量梯度下降和RMSprop的优化算法。
在每一轮迭代中，Adam算法首先计算梯度的一阶矩和二阶矩的估计值，然后使用偏差修正后的一阶矩和二阶矩的估计值来更新权重和偏置。
\begin{equation}
    \begin{aligned}
        v_{\d \mathrm{var}} &= \beta_1 v_{\d \mathrm{var}} + (1 - \beta_1)\d \mathrm{var} \\
        s_{\d \mathrm{var}} &= \beta_2 s_{\d \mathrm{var}} + (1 - \beta_2)(\d \mathrm{var})^2 \\
        v_{\d \mathrm{var}}^{\mathrm{corrected}} &= \frac{v_{\d \mathrm{var}}}{1 - \beta_1^t} \\
        s_{\d \mathrm{var}}^{\mathrm{corrected}} &= \frac{s_{\d \mathrm{var}}}{1 - \beta_2^t} \\
        \d \mathrm{var} &= \frac{v_{\d \mathrm{var}}^{\mathrm{corrected}}}{\sqrt{s_{\d \mathrm{var}}^{\mathrm{corrected}}} + \varepsilon}
    \end{aligned}
\end{equation}
通常取 $\beta_1 = 0.9$，$\beta_2 = 0.999$，$\varepsilon = 10^{-8}$。有时候也可以忽略偏差修正。

\begin{figure}[h!bt]
    \centering
    \subfigure{
        \begin{minipage}[t]{0.46\textwidth}
            \centering
            \includegraphics[width=\textwidth]{adam_1.pdf}
        \end{minipage}
    }%
    \subfigure{
        \begin{minipage}[t]{0.46\textwidth}
            \centering
            \includegraphics[width=\textwidth]{adam_2.pdf}
        \end{minipage}
    }%
    \centering
    \caption{Adam Optimization Algorithm}
    \label{fig:adam}
\end{figure}

%%%%
\subsection{Learning Rate Decay}

\textbf{学习率衰减（Learning Rate Decay）}是另一种优化训练速率的方法，可以加快梯度下降的收敛速度。
其基本思想是，随着训练的进行，学习率逐渐减小，这样可以在训练初期快速接近代价函数的最小值，然后在训练后期更加精细地搜索代价函数的最小值。

一个常用的学习率衰减公式为
\begin{equation}
    \alpha = \frac{1}{1 + \mathtt{decay\_rate} \times \mathtt{epoch\_num}} \times \alpha_0
\end{equation}

此外，还有指数衰减学习率、开方衰减学习率、离散衰减学习率等方法，这里不再赘述。

%%%%
\subsection{The Problem of Local Optima}

在训练神经网络时，通常会使用梯度下降算法来最小化代价函数，从而找到代价函数的最小值。
但是，梯度下降法最终会收敛到梯度约为0的点，而这些点不一定是代价函数的全局最小值。

一种常见的收敛点是\textbf{局部最小值（Local Minimum）}，即在某个点附近代价函数的值最小，但在其他点附近的代价函数的值可能更小。

另一种常见的收敛点是\textbf{鞍点（Saddle Point）}，即在某个点附近代价函数的梯度为0，虽然其在某些维度上为极小值，但在其他维度上为极大值。
\begin{figure}[h!bt]
    \centering
    \begin{minipage}[t]{0.48\textwidth}
        \centering
        \includegraphics[width=0.9\textwidth]{local_minimum.pdf}
        \caption{Local Minimum}
        \label{fig:local_minimum}
    \end{minipage}
    \begin{minipage}[t]{0.48\textwidth}
        \centering
        \includegraphics[width=0.9\textwidth]{saddle_point.pdf}
        \caption{Saddle Point}
        \label{fig:saddle_point}
    \end{minipage}
\end{figure}

此外，\textbf{Plateaus}（停滞区）也是梯度下降法的一个问题，即代价函数在某些区域的梯度很小，导致梯度下降法收敛缓慢。
在这样的区域中，代价函数的变化在多轮迭代中的变化很小，容易被误认为是收敛点。

%%%
\section{Hyperparameter Tuning}

在调整超参数（Tuning Hyperparameters）时，通常应先确定各个超参数的范围，在一个超立方体中进行搜索（区域型搜索）。
当找到一个较好的超参数组合时，可以缩小范围，在其附近进行更加精细的搜索，直到找到最优的超参数组合。

相对于均匀搜索（Grid Search），随机搜索（Random Search）是一种更好的超参数搜索方法，可以减少重要性较低的超参数浪费的搜索次数。
\begin{figure}[h!bt]
    \centering
    \begin{minipage}[t]{0.45\textwidth}
        \centering
        \includegraphics[width=0.8\textwidth]{tuning_grid.pdf}
        \caption{Grid Search}
    \end{minipage}
    \begin{minipage}[t]{0.45\textwidth}
        \centering
        \includegraphics[width=0.8\textwidth]{tuning_random.pdf}
        \caption{Random Search}
    \end{minipage}
\end{figure}

在调整超参数时，还要选取合适的比例尺（Scale）。
对于某些参数，相对于在某个范围内均匀搜索，更好的方法是在对数尺度上均匀搜索（在指数上均匀选取随机数），例如
\begin{align}
    \alpha &= \mathtt{\textcolor{green}{10} *\!* \ np.random.uniform\textcolor{yellow}{(}low=\textcolor{green}{-4}, high=\textcolor{green}{0}\textcolor{yellow}{)}} \\
    \beta_2 &= \mathtt{\textcolor{green}{1} - \textcolor{green}{10} *\!* \ np.random.uniform\textcolor{yellow}{(}low=\textcolor{green}{-3}, high=\textcolor{green}{-1}\textcolor{yellow}{)}}
\end{align}

对于一个项目，超参数的调整通常可根据算力情况分为两种方案，
一种是手工调整单个模型，即在训练过程中，人工观察代价函数的变化，根据代价函数的变化调整超参数。
另一种则是同时训练多个使用不同超参数的模型，然后选择其中表现最好的模型。

%%%
\section{Batch Normalization}
\index{Batch Normalization}

%%%%
\subsection{Normalization Activation Values}

在之前的章节中，我们介绍了如何对输入数据进行归一化处理。
在神经网络中，每一层的输出都会变成下一层的输入，因此也可以对每一层的输出进行归一化处理，来避免梯度消失和梯度爆炸的问题。
这就是\textbf{批量归一化（Batch Normalization）}。

在实际使用中，通常对线性函数的输出（激活函数的输入）而不是激活函数的输出进行归一化处理，避免激活函数的效果被削弱。
\begin{equation}
    \begin{aligned}
        \mu^{[l]} &= \frac{1}{m}\sum_{i=1}^m z^{[l](i)} \\
        \sigma^{2[l]} &= \frac{1}{m}\sum_{i=1}^m (z^{[l](i)} - \mu)^2 \\
        Z^{[l]}_{\mathrm{norm}} &= \frac{Z^{[l]} - \mu}{\sqrt{\sigma^2 + \varepsilon}}
    \end{aligned}
    \label{eq:batch_norm}
\end{equation}
注意归一化是在各个样本这个维度上进行的，即对每个样本的同一层的输出进行归一化处理。
上式中的$\varepsilon$是数值稳定性参数，通常取$10^{-8}$。

使用式~\eqref{eq:batch_norm} 对$Z^{[l]}$进行归一化处理后，$Z^{[l]}_{\mathrm{norm}}$具有零均值和单位方差，但是这不一定适合于后续的激活函数（例如 Sigmoid 函数，0.5的均值可能更适合）。
为了使$Z^{[l]}_{\mathrm{norm}}$具有任意均值和方差，还需要对其进行缩放和平移，即
\begin{equation}
    \forall i \in \{1, \ldots, m\}, \quad \tilde{z}^{[l](i)} = \tikzmarknode{gamma}{\gamma^{[l]}} \odot z^{[l](i)}_{\mathrm{norm}} + \tikzmarknode{beta}{\beta^{[l]}}
    \annotatetwo[yshift=-1em]{below,label below}{gamma}{beta}{$n^{[l]}\times 1$}
    \vspace{1.5em}
\end{equation}
这样处理后，$\tilde{Z}^{[l]}$在行方向上的均值为$\beta^{[l]}$，标准差为$\gamma^{[l]}$。
$\gamma^{[l]}$和$\beta^{[l]}$\footnote{这里的$\beta^{[l]}$与矩估计中的衰减率是完全不同的两个量，只是使用了相同的符号。}
是可以训练的参数，可以通过反向传播来更新。

%%%%
\subsection{Fitting Batch Norm into a Neural Network}

要将批量归一化应用于神经网络，需要对每一层的输出进行归一化处理，即在前向传播中用$\tilde{Z}^{[l]}$替代原来的$Z^{[l]}$，然后再进行激活函数的计算。
\begin{align}
    Z^{[l]} &= W^{[l]}A^{[l-1]} \textcolor{lightgray}{\vphantom{1}+ \bigl[ \leftarrow \vphantom{1}} \cancel{\textcolor{lightgray}{b^{[l]}}} \textcolor{lightgray}{\vphantom{1} \rightarrow \bigr]} 
    \label{eq:batch_norm_zl} \\
    \mu^{[l]} &= \frac{1}{m}\sum_{i=1}^m Z^{[l](i)} 
    \label{eq:batch_norm_mu} \\
    \sigma^{2[l]} &= \frac{1}{m}\sum_{i=1}^m (Z^{[l](i)} - \mu)^2 
    \label{eq:batch_norm_sigma} \\
    Z^{[l]}_{\mathrm{norm}} &= \frac{Z^{[l]} - \mu}{\sqrt{\sigma^2 + \varepsilon}}
    \label{eq:batch_norm_znorm}
\end{align}
\begin{align}
    \vcenter{\hbox{$\tilde{Z}^{[l]}$}} &\vcenter{\hbox{$\vphantom{1}=\vphantom{1}$}} \begin{bmatrix} \gamma^{[l]} & \gamma^{[l]} & \cdots & \gamma^{[l]}\end{bmatrix}_{\substack{\scriptstyle n^{[l]}\times m}} \vcenter{\hbox{$\vphantom{1}\odot Z^{[l]}_{\mathrm{norm}} +\vphantom{1}$}} \begin{bmatrix} \beta^{[l]} & \beta^{[l]} & \cdots & \beta^{[l]} \end{bmatrix}_{\substack{\scriptstyle n^{[l]}\times m}} 
    \label{eq:batch_norm_ztilde} \\
    A^{[l]} &= g^{[l]}(\tilde{Z}^{[l]})
    \label{eq:batch_norm_al}
\end{align}
注意此时省略了偏置$b^{[l]}$，因为在归一化处理后，偏置的作用被消除了。
在代码实现中，可以将偏置$b^{[l]}$和梯度$\d b^{[l]}$直接设置为全0。

要实现应用批量归一化的反向传播，应明确目标，对于第$l$层，已知$\dfrac{\d J}{\d A^{[l]}}$，需要计算$\dfrac{\partial J}{\partial W^{[l]}}$、$\dfrac{\d J}{\d A^{[l-1]}}$、$\dfrac{\partial J}{\partial \gamma^{[l]}}$和$\dfrac{\partial J}{\partial \beta^{[l]}}$。

首先，类似于式~\eqref{eq:backpropagation_m_derivative_conc}，下面的关系成立
\begin{align}
    \dfrac{\partial L^{(i)}}{\partial z^{[l](i)}} = m \dfrac{\partial J}{\partial z^{[l](i)}} 
    \label{eq:batch_norm_zl_m} \\
    \dfrac{\partial L^{(i)}}{\partial \tilde{z}^{[l](i)}} = m \dfrac{\partial J}{\partial \tilde{z}^{[l](i)}}
    \label{eq:batch_norm_ztilde_m}
\end{align}

先求取$\dfrac{\partial J}{\partial \gamma^{[l]}}$和$\dfrac{\partial J}{\partial \beta^{[l]}}$。
式~\eqref{eq:batch_norm_al} 表明
\begin{equation}
    \dfrac{\d J}{\d \tilde{Z}^{[l]}} = g^{[l]\prime}(\tilde{Z}^{[l]}) \odot \dfrac{\d J}{\d A^{[l]}}
\end{equation}
对第$i$个样本，式~\eqref{eq:batch_norm_ztilde} 可以表示为
\begin{equation}
    \tilde{z}^{[l](i)} = \gamma^{[l]} \odot z^{[l](i)}_{\mathrm{norm}} + \beta^{[l]}
    \label{eq:batch_norm_ztilde_i}
\end{equation}
进而
\begin{align}
    \dfrac{\partial L^{(i)}}{\partial \gamma^{[l]}} &= \dfrac{\partial \tilde{z}^{[l](i)}}{\partial \gamma^{[l]}} \dfrac{\partial L^{(i)}}{\partial \tilde{z}^{[l](i)}} = z^{[l](i)}_{\mathrm{norm}} \odot \dfrac{\partial L^{(i)}}{\partial \tilde{z}^{[l](i)}} \\
    \dfrac{\partial L^{(i)}}{\partial \beta^{[l]}} &= \dfrac{\partial \tilde{z}^{[l](i)}}{\partial \beta^{[l]}} \dfrac{\partial L^{(i)}}{\partial \tilde{z}^{[l](i)}} = \dfrac{\partial L^{(i)}}{\partial \tilde{z}^{[l](i)}}
\end{align}
考虑式~\eqref{eq:batch_norm_ztilde_m} 的关系，
\begin{equation}
    \begin{aligned}
        \dfrac{\partial J}{\partial \gamma^{[l]}} 
        &= \dfrac{1}{m} \sum_{i=1}^m \dfrac{\partial L^{(i)}}{\partial \gamma^{[l]}} \\
        &= \dfrac{1}{m} \sum_{i=1}^m z^{[l](i)}_{\mathrm{norm}} \odot \dfrac{\partial L^{(i)}}{\partial \tilde{z}^{[l](i)}} \\
        &= \dfrac{1}{m} \sum_{i=1}^m z^{[l](i)}_{\mathrm{norm}} \odot m \dfrac{\partial J}{\partial \tilde{z}^{[l](i)}} \\
        &= \tikzmarknode{dgamma}{\sum_{i=1}^m z^{[l](i)}_{\mathrm{norm}} \odot \dfrac{\partial J}{\partial \tilde{z}^{[l](i)}}}
    \end{aligned}
    \renewcommand{\eqnannotationstrut}{\rule[-0.7\baselineskip]{0pt}{1.5\baselineskip}} % 延展注释框
    \annotate[yshift=0em]{below}{dgamma}{相当于$Z^{[l]}_{\mathrm{norm}}\odot\dfrac{\d J}{\d \tilde{Z}^{[l]}}$沿水平方向求和}
    \renewcommand{\eqnannotationstrut}{\strut} % package default
    \vspace{2em}
\end{equation}
\begin{equation}
    \begin{aligned}
        \dfrac{\partial J}{\partial \beta^{[l]}} 
        &= \dfrac{1}{m} \sum_{i=1}^m \dfrac{\partial L^{(i)}}{\partial \beta^{[l]}} \\
        &= \dfrac{1}{m} \sum_{i=1}^m \dfrac{\partial L^{(i)}}{\partial \tilde{z}^{[l](i)}} \\
        &= \dfrac{1}{m} \sum_{i=1}^m m \dfrac{\partial J}{\partial \tilde{z}^{[l](i)}} \\
        &= \tikzmarknode{dbeta}{\sum_{i=1}^m \dfrac{\partial J}{\partial \tilde{z}^{[l](i)}}}
    \end{aligned}
    \renewcommand{\eqnannotationstrut}{\rule[-0.7\baselineskip]{0pt}{1.5\baselineskip}} % 延展注释框
    \annotate[yshift=0em]{below}{dbeta}{相当于$\dfrac{\d J}{\d \tilde{Z}^{[l]}}$沿水平方向求和}
    \renewcommand{\eqnannotationstrut}{\strut} % package default
    \vspace{2em}
\end{equation}

接下来求取$\dfrac{\partial J}{\partial W^{[l]}}$和$\dfrac{\d J}{\d A^{[l-1]}}$。
再次考虑式~\eqref{eq:batch_norm_ztilde_i} 以及式~\eqref{eq:batch_norm_ztilde_m} 的关系，
\begin{equation}
    \dfrac{\partial L^{(i)}}{\partial z^{[l](i)}_{\mathrm{norm}}} 
    = \gamma^{[l]} \odot \dfrac{\partial L^{(i)}}{\partial \tilde{z}^{[l](i)}}
    = m \cdot \gamma^{[l]} \odot \dfrac{\partial J}{\partial \tilde{z}^{[l](i)}}
\end{equation}
对第$i$个样本，式~\eqref{eq:batch_norm_znorm} 可以表示为
\begin{equation}
    z^{[l](i)}_{\mathrm{norm}} = \dfrac{z^{[l](i)} - \mu}{\sqrt{\sigma^2 + \varepsilon}}
    \label{eq:batch_norm_znorm_i}
\end{equation}
从中可得到
\begin{equation}
    \dfrac{\partial L^{(i)}}{\partial \sigma^{2[l]}} 
    = \dfrac{\partial z^{[l](i)}_{\mathrm{norm}}}{\partial \sigma^{2[l]}} \odot \dfrac{\partial L^{(i)}}{\partial z^{[l](i)}_{\mathrm{norm}}} 
    = -\dfrac{1}{2} \dfrac{z^{[l](i)} - \mu}{(\sigma^{2[l]} + \varepsilon)^{\frac{\scriptstyle 3}{\scriptstyle 2}}} \odot \dfrac{\partial L^{(i)}}{\partial z^{[l](i)}_{\mathrm{norm}}}
\end{equation}
考虑式~\eqref{eq:batch_norm_znorm_i} 和式~\eqref{eq:batch_norm_sigma}，可得
\begin{equation}
    \begin{aligned}
        \dfrac{\partial L^{(i)}}{\partial \mu^{[l]}} 
        &= \dfrac{\partial z^{[l](i)}_{\mathrm{norm}}}{\partial \mu^{[l]}} \odot \dfrac{\partial L^{(i)}}{\partial z^{[l](i)}_{\mathrm{norm}}} + \dfrac{\partial \sigma^{2[l]}}{\partial \mu^{[l]}} \odot \dfrac{\partial L^{(i)}}{\partial \sigma^{2[l]}} \\
        &= -\dfrac{1}{\sqrt{\sigma^{2[l]} + \varepsilon}} \odot \dfrac{\partial L^{(i)}}{\partial z^{[l](i)}_{\mathrm{norm}}} - \dfrac{2}{m} \sum_{i=1}^m (z^{[l](i)} - \mu^{[l]}) \odot \dfrac{\partial L^{(i)}}{\partial \sigma^{2[l]}}
    \end{aligned}
\end{equation}
运用链式法则，
\begin{equation}
    \begin{aligned}
        \dfrac{\partial L^{(i)}}{\partial z^{[l](i)}} 
        &= \dfrac{\partial z^{[l](i)}_{\mathrm{norm}}}{\partial z^{[l](i)}} \odot \dfrac{\partial L^{(i)}}{\partial z^{[l](i)}_{\mathrm{norm}}} + \dfrac{\partial \sigma^{2[l]}}{\partial z^{[l](i)}} \odot \dfrac{\partial L^{(i)}}{\partial \sigma^{2[l]}} + \dfrac{\partial \mu^{[l]}}{\partial z^{[l](i)}} \odot \dfrac{\partial L^{(i)}}{\partial \mu^{[l]}} \\
        &= \dfrac{1}{\sqrt{\sigma^{2[l]} + \varepsilon}} \odot \dfrac{\partial L^{(i)}}{\partial z^{[l](i)}_{\mathrm{norm}}} + \dfrac{2}{m} (z^{[l](i)} - \mu^{[l]}) \odot \dfrac{\partial L^{(i)}}{\partial \sigma^{2[l]}} + \dfrac{1}{m} \dfrac{\partial L^{(i)}}{\partial \mu^{[l]}}
    \end{aligned}
\end{equation}
进而可合并得到
\begin{equation}
    \dfrac{\partial J}{\partial Z^{[l]}} 
    = \left[ \dfrac{\partial J}{\partial z^{[l](1)}}, \dfrac{\partial J}{\partial z^{[l](2)}}, \cdots, \dfrac{\partial J}{\partial z^{[l](m)}} \right]
    = \dfrac{1}{m} \left[ \dfrac{\partial L^{(i)}}{\partial z^{[l](1)}}, \dfrac{\partial L^{(i)}}{\partial z^{[l](2)}}, \cdots, \dfrac{\partial L^{(i)}}{\partial z^{[l](m)}} \right]
\end{equation}
而根据式~\eqref{eq:batch_norm_zl}，可以直接得到
\begin{align}
    \dfrac{\partial J}{\partial W^{[l]}} &= \dfrac{\d J}{\d Z^{[l]}} A^{[l-1] \mathrm{T}} \\
    \dfrac{\d J}{\d A^{[l-1]}} &= W^{[l] \mathrm{T}} \dfrac{\d J}{\d Z^{[l]}}
\end{align}
代入$\dfrac{\partial J}{\partial Z^{[l]}}$，即可得出所求的$\dfrac{\partial J}{\partial W^{[l]}}$和$\dfrac{\d J}{\d A^{[l-1]}}$。
具体的代码实现在此不再赘述。

在实际应用中，Batch Normalization一般会和mini-batch梯度下降一起使用。
这时，批量归一化会具有一定正则化的效果，这是因为在第$t$个 \verb|mini_batch| 中，$Z^{[l]\{t\}}$ 的均值和方差是基于这个 \verb|mini_batch| 计算的，而不是基于整个训练集。这会增加一些噪声，使网络不依赖于特定的神经元。

在测试样本很少时（例如只有1个），进行归一化（计算均值和标准差）几乎没有意义。
可使用训练时各 \verb|mini_batch| 上的指数加权平均值$\hat{\mu}$和$\hat{\sigma}$来替代（需要在训练时保存这两个值）。
